<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>CodePen - MediaPipe HandLandmarker Task for web</title>
    <link rel="shortcut icon" type="image/x-icon" href="https://cpwebassets.codepen.io/assets/favicon/favicon-aec34940fbc1a6e787974dcd360f2c6b63348d4b1f4e06c77743096d55480f33.ico">
    <link rel="mask-icon" type="image/x-icon" href="https://cpwebassets.codepen.io/assets/favicon/logo-pin-b4b4269c16397ad2f0f7a01bcdf513a1994f4c94b8af2f191c09eb0d601762b1.svg" color="#111">
    <script src="https://cpwebassets.codepen.io/assets/common/stopExecutionOnTimeout-2c7831bb44f98c1391d6a4ffda0e1fd302503391ca806e7fcc7b9b87197aec26.js"></script>
    <link rel="stylesheet" href="css/style.css">

    <script>
        window.console = window.console || function(t) {};
    </script>
</head>
  
<body translate="no">

<link href="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.css" rel="stylesheet">
<script src="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
  
<section id="demos" class="">
    <h1>Demo: v2 Webcam continuous hands landmarks detection</h1>
    <p>Hold your hand in front of your webcam to get real-time hand landmarker detection.<br>Click <b>enable webcam</b> below and grant access to the webcam if prompted.</p>

    <div id="liveView" class="videoView">
        <button id="webcamButton" class="mdc-button mdc-button--raised">
            <span class="mdc-button__ripple"></span>
            <span class="mdc-button__label">ENABLE WEBCAM</span>
        </button>
        <div style="position: relative;">
            <video id="webcam" style="position: abso" autoplay="" playsinline=""></video>
            <canvas class="output_canvas" id="output_canvas" style="position: absolute; left: 0px; top: 0px;"></canvas>
        </div>
    </div>

    <div id="landmarksOutput"></div> <!-- Вывод landmarks -->
</section>

<script id="rendered-js" type="module">
    import { HandLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";
    const demosSection = document.getElementById("demos");
    const landmarksOutput = document.getElementById("landmarksOutput"); // Получаем div для вывода landmarks

    let handLandmarker = undefined;
    let runningMode = "VIDEO";
    let enableWebcamButton;
    let webcamRunning = false;

    // Before we can use HandLandmarker class we must wait for it to finish
    // loading. Machine Learning models can be large and take a moment to
    // get everything needed to run.
    const createHandLandmarker = async () => {
        const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm");
        handLandmarker = await HandLandmarker.createFromOptions(vision, {
            baseOptions: {
                modelAssetPath: `https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task`,
                delegate: "GPU"
            },
            runningMode: runningMode,
            numHands: 2
        });
        demosSection.classList.remove("invisible");
    };
    createHandLandmarker();

    // Continuously grab image from webcam stream and detect it.
    const video = document.getElementById("webcam");
    const canvasElement = document.getElementById("output_canvas");
    const canvasCtx = canvasElement.getContext("2d");

    // Check if webcam access is supported.
    const hasGetUserMedia = () => { var _a; return !!((_a = navigator.mediaDevices) === null || _a === void 0 ? void 0 : _a.getUserMedia); };
    
    // If webcam supported, add event listener to button for when user
    // wants to activate it.
    if (hasGetUserMedia()) {
        enableWebcamButton = document.getElementById("webcamButton");
        enableWebcamButton.addEventListener("click", enableCam);
    }
    else {
        console.warn("getUserMedia() is not supported by your browser");
    }

    // Enable the live webcam view and start detection.
    function enableCam(event) {
        if (!handLandmarker) {
            console.log("Wait! objectDetector not loaded yet.");
            return;
        }
        if (webcamRunning === true) {
            webcamRunning = false;
            enableWebcamButton.innerText = "ENABLE PREDICTIONS";
        }
        else {
            webcamRunning = true;
            enableWebcamButton.innerText = "DISABLE PREDICTIONS";
        }

        // getUsermedia parameters.
        const constraints = {
            video: {
                facingMode: 'environment' // Use back camera
            }
        };

        // Activate the webcam stream.
        navigator.mediaDevices.getUserMedia(constraints).then((stream) => {
            video.srcObject = stream;
            video.addEventListener("loadeddata", predictWebcam);
        });
    }

    let lastVideoTime = -1;
    let results = undefined;

    async function predictWebcam() {
        canvasElement.style.width = video.videoWidth;
        canvasElement.style.height = video.videoHeight;
        canvasElement.width = video.videoWidth;
        canvasElement.height = video.videoHeight;

        // Now let's start detecting the stream.
        if (runningMode === "IMAGE") {
            runningMode = "VIDEO";
            await handLandmarker.setOptions({ runningMode: "VIDEO" });
        }

        let startTimeMs = performance.now();
        if (lastVideoTime !== video.currentTime) {
            lastVideoTime = video.currentTime;
            results = handLandmarker.detectForVideo(video, startTimeMs);
            console.log(video);
        }

        canvasCtx.save();
        canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

        if (results.landmarks) {
            const formattedResults = {
                handedness: results.landmarks.map(hand => ({
                    categories: [{
                        index: 0,
                        score: 0.98396,
                        categoryName: hand.Handedness.Categories[0].categoryName
                    }]
                })),
                landmarks: results.landmarks.map(hand => ({
                    landmarks: hand.Landmarks.map(landmark => ({
                        x: landmark.x,
                        y: landmark.y,
                        z: landmark.z
                    }))
                }))
            };

            // Выводим landmarks в HTML
            landmarksOutput.innerHTML = `
                <h2>Landmarks:</h2>
                ${formattedResults.landmarks.map(hand => `
                    <div class="hand">
                        <h3>Handedness:</h3>
                        <p>Category: ${hand.Handedness.Categories[0].categoryName}</p>
                        <p>Score: ${hand.Handedness.Categories[0].score}</p>
                        <h3>Landmarks:</h3>
                        <ul>
                            ${hand.landmarks.map(landmark => `
                                <li>
                                    x: ${landmark.x}<br>
                                    y: ${landmark.y}<br>
                                    z: ${landmark.z}<br>
                                </li>
                            `).join('')}
                        </ul>
                    </div>
                `).join('')}
            `;
        }
        
        canvasCtx.restore();
        // Call this function again to keep predicting when the browser is ready.
        if (webcamRunning === true) {
            window.requestAnimationFrame(predictWebcam);
        }
    }
</script>
  
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm/vision_wasm_internal.js" crossorigin="anonymous"></script>
</body>
</html>
