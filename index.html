<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>CodePen - MediaPipe HandLandmarker Task for web</title>
    <link rel="shortcut icon" type="image/x-icon" href="https://cpwebassets.codepen.io/assets/favicon/favicon-aec34940fbc1a6e787974dcd360f2c6b63348d4b1f4e06c77743096d55480f33.ico">
    <link rel="mask-icon" type="image/x-icon" href="https://cpwebassets.codepen.io/assets/favicon/logo-pin-b4b4269c16397ad2f0f7a01bcdf513a1994f4c94b8af2f191c09eb0d601762b1.svg" color="#111">
    <script src="https://cpwebassets.codepen.io/assets/common/stopExecutionOnTimeout-2c7831bb44f98c1391d6a4ffda0e1fd302503391ca806e7fcc7b9b87197aec26.js"></script>
    <link rel="stylesheet" href="css/style.css">

    <script>
        window.console = window.console || function(t) {};
    </script>
</head>
  
<body translate="no">

<script type="importmap">
    {
        "imports": {
        "three": "https://cdn.jsdelivr.net/npm/three@0.163.0/build/three.module.js",
        "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.163.0/examples/jsm/"
        }
    }
    </script>

<link href="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.css" rel="stylesheet">
<script src="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/three@0.163.0/build/three.min.js"></script>
  
<section id="demos" class="">
    <h1>Demo: v8 Webcam continuous hands landmarks detection</h1>
    <p>Hold your hand in front of your webcam to get real-time hand landmarker detection.<br>Click <b>enable webcam</b> below and grant access to the webcam if prompted.</p>

    <div id="liveView" class="videoView">
        <button id="webcamButton" class="mdc-button mdc-button--raised">
            <span class="mdc-button__ripple"></span>
            <span class="mdc-button__label">ENABLE WEBCAM</span>
        </button>
        <div id="try_on" style="position: relative;">
            <video id="webcam" style="position: abso" autoplay="" playsinline=""></video>
            <canvas class="output_canvas" id="output_canvas" style="position: absolute; left: 0px; top: 0px;"></canvas>
            <div id="overlay"></div>
        </div>
    </div>

    <div id="landmarksOutput"></div> <!-- Вывод landmarks -->
</section>

<script id="rendered-js" type="module">
    import { HandLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";
    import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
    import * as THREE from 'three';
    const demosSection = document.getElementById("demos");
    const landmarksOutput = document.getElementById("landmarksOutput"); // Получаем div для вывода landmarks

    let handLandmarker = undefined;
    let runningMode = "VIDEO";
    let enableWebcamButton;
    let webcamRunning = false;
    let lastVideoTime = -1;
    let results = undefined; // Объявляем переменную results
    let modelAdded = false;
    let model = new THREE.Object3D( );
    let position = new Object;

    // Before we can use HandLandmarker class we must wait for it to finish
    // loading. Machine Learning models can be large and take a moment to
    // get everything needed to run.
    const createHandLandmarker = async () => {
        const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm");
        handLandmarker = await HandLandmarker.createFromOptions(vision, {
            baseOptions: {
                modelAssetPath: `https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task`,
                delegate: "GPU"
            },
            runningMode: runningMode,
            numHands: 2
        });
        demosSection.classList.remove("invisible");
    };
    createHandLandmarker();

    // Continuously grab image from webcam stream and detect it.
    const video = document.getElementById("webcam");
    const canvasElement = document.getElementById("output_canvas");
    const canvasCtx = canvasElement.getContext("2d");

    // Check if webcam access is supported.
    const hasGetUserMedia = () => { var _a; return !!((_a = navigator.mediaDevices) === null || _a === void 0 ? void 0 : _a.getUserMedia); };
    
    // If webcam supported, add event listener to button for when user wants to activate it.
    if (hasGetUserMedia()) {
        enableWebcamButton = document.getElementById("webcamButton");
        enableWebcamButton.addEventListener("click", toggleWebcam);
    }
    else {
        console.warn("getUserMedia() is not supported by your browser");
    }

    // Toggle webcam and processing
    function toggleWebcam() {
        if (webcamRunning) {
            // Stop webcam and processing
            video.srcObject.getTracks().forEach(track => track.stop()); // Остановка всех треков видео
            video.srcObject = null;
            video.removeEventListener("loadeddata", predictWebcam);
            enableWebcamButton.innerText = "ENABLE WEBCAM";
            webcamRunning = false;
        } else {
            // Start webcam and processing
            const constraints = {
                video: {
                    facingMode: 'environment' // Use back camera
                }
            };
            navigator.mediaDevices.getUserMedia(constraints).then((stream) => {
                video.srcObject = stream;
                video.addEventListener("loadeddata", predictWebcam);
                document.getElementById("try_on").style.display = "block";
                enableWebcamButton.innerText = "DISABLE WEBCAM";
                webcamRunning = true;
            }).catch((error) => {
                console.error("Error accessing webcam:", error);
            });
        }
    }

    // Detect landmarks in webcam video
    async function predictWebcam() {
        // Проверяем, что handLandmarker создан
        if (!handLandmarker || !webcamRunning) {
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            model.visible = false;
            console.log("HandLandmarker is not loaded or webcam is not running.");
            return;
        }

        canvasElement.style.width = video.videoWidth;
        canvasElement.style.height = video.videoHeight;
        canvasElement.width = video.videoWidth;
        canvasElement.height = video.videoHeight;

        const currentTime = video.currentTime;
        if (currentTime !== lastVideoTime) {
            lastVideoTime = currentTime;
            results = handLandmarker.detectForVideo(video, performance.now());
            console.log('results: ', results);  
        }

        canvasCtx.save();
        canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

        // Отрисовываем лэндмарки, создаем модель, позиционируем ее относительно лэндмарки
        if (results && results.landmarks) {
            for (const landmarks of results.landmarks) {
                drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, {
                    color: "#FFFFFF",
                    lineWidth: 5
                });
                drawLandmarks(canvasCtx, landmarks, { color: "#00BFFF", lineWidth: 2 });
            }
            if(!modelAdded && results.landmarks.length !== 0) {
                addModel();
                modelAdded = true;
            }
            else if (modelAdded && results.landmarks.length !== 0) {
                ////
                //// Приведение к общей системе координат
                ////
                position.x = (results.landmarks[0][14].x) * 2 - 1; // Преобразование x в диапазон [-1, 1]
                position.y = (1 - results.landmarks[0][14].y) * 2 - 1; // Преобразование y в диапазон [-1, 1]
                position.z = 0; // Без Z позиция не копируется
                ////
                model.scale.set(results.landmarks[0][14].z*2, results.landmarks[0][14].z*2, results.landmarks[0][14].z*2);
                
                model.position.copy(position);
                model.visible = true; // Показываем модель
            }
            else if (modelAdded && results.landmarks.length == 0) {
                model.visible = false; // Скрываем модель
            }
        }

        canvasCtx.restore();
        // Call this function again to keep predicting when the browser is ready.
        if (webcamRunning) {
            window.requestAnimationFrame(predictWebcam);
        }
    }

    // Функция для добавления модели на сцену
    function addModel() {
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(20, canvasElement.width / canvasElement.height, 0.1, 100);
        camera.position.z = 5;
        const renderer = new THREE.WebGLRenderer({ alpha: true });
        renderer.setSize(canvasElement.width, canvasElement.height);
        renderer.domElement.style.position = "absolute";
        renderer.domElement.style.top = "0";
        renderer.domElement.style.left = "0";
        renderer.physicallyCorrectLights = true;

        document.getElementById("overlay").appendChild(renderer.domElement);

        const ambientLight = new THREE.AmbientLight(0xFFFFFF);
        ambientLight.intensity = 20;
        scene.add( ambientLight );
        
        const loader = new GLTFLoader();
        loader.load(
            'app/models/simple_ring.glb',
            function (gltf) {
                model = gltf.scene;
                model.traverse((object) => {
                    if (object.isMesh) {
                    const map = object.material && object.material.map ? object.material.map : null
                    const material = new THREE.MeshStandardMaterial;
                    material.map = map
                    object.material = material;
                    }
                });
                
                model.scale.set(0.3, 0.3, 0.3);
                scene.add(model);
            },
            undefined,
            function (error) {
                console.error('An error happened', error);
            }
        );

        function animate() {
            requestAnimationFrame(animate);
            if (model) {
                model.rotation.x += 0.01;
                model.rotation.y += 0.01;
            }
            renderer.render(scene, camera);
        }
        animate();
    }

</script>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm/vision_wasm_internal.js" crossorigin="anonymous"></script>
</body>
</html>